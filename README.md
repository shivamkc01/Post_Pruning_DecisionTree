


Pruning is one of the techniques that is used to overcome our problem of Overfitting. Pruning, in its literal sense, is a practice which involves the selective removal of certain parts of a tree(or plant), such as branches, buds, or roots, to improve the treeâ€™s structure, and promote healthy growth. This is exactly what Pruning does to our Decision Trees as well. It makes it versatile so that it can adapt if we feed any new kind of data to it, thereby fixing the problem of overfitting.

It reduces the size of a Decision Tree which might slightly increase your training error but drastically decrease your testing error, hence making it more adaptable.

If you want to learn more about Post and Pre Pruning then go to this webiste: - https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html

Here some videos links also related to Post and Pre Pruning decision tree
1-https://www.youtube.com/watch?v=SLOyyFHbiqo&t=339s


2-https://www.youtube.com/watch?v=D0efHEJsfHo
